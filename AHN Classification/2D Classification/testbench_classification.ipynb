{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled GPU Available? True\n",
      "GPU Number: 1\n",
      "Current GPU Index: 0\n",
      "GPU Type: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "GPU Capability: (8, 6)\n",
      "Is GPU Initialized yet? True\n",
      "2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is CUDA enabled GPU Available?\", torch.cuda.is_available())\n",
    "print(\"GPU Number:\", torch.cuda.device_count())\n",
    "print(\"Current GPU Index:\", torch.cuda.current_device())\n",
    "print(\"GPU Type:\", torch.cuda.get_device_name(device=None))\n",
    "print(\"GPU Capability:\", torch.cuda.get_device_capability(device=None))\n",
    "print(\"Is GPU Initialized yet?\", torch.cuda.is_initialized())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import h5py\n",
    "import scipy\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import PIL.Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Models and Check Inference Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Custom Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = get_pretrained_model('', \n",
    "                                            'convnext_xlarge.fb_in22k_ft_in1k', \n",
    "                                            'import_TIMM', \n",
    "                                            True, \n",
    "                                            3, \n",
    "                                            5, \n",
    "                                            'Sigmoid', \n",
    "                                            True, \n",
    "                                            False, \n",
    "                                            1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = get_pretrained_model('', \n",
    "                                            'PHCNet', \n",
    "                                            'custom_CNN', \n",
    "                                            True, \n",
    "                                            3, \n",
    "                                            5, \n",
    "                                            'Sigmoid', \n",
    "                                            True, \n",
    "                                            False, \n",
    "                                            1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348168458\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in classification_model.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102533\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in classification_model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "FPS 0.09842095920044253\n",
      "Time 10.160437452793122\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "device = torch.device('cpu')\n",
    "input_shape = (5, 3, 512, 512)\n",
    "model = classification_model\n",
    "image = torch.randn(input_shape)\n",
    "# image = image.type(torch.LongTensor)\n",
    "image.to(device)\n",
    "init = time.time()\n",
    "iters = 100\n",
    "with torch.no_grad():\n",
    "    for i in range(iters):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        output = model(image)\n",
    "        print(i)\n",
    "end = time.time() - init\n",
    "print(f\"FPS {1/(end/iters)}\")\n",
    "print(f\"Time {end/iters}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
